\documentclass[10pt]{extarticle}
\renewcommand{\arraystretch}{1.5}
\renewcommand{\baselinestretch}{1.5}
\usepackage[onehalfspacing]{setspace}
\setlength{\parindent}{0em}
\setlength{\parskip}{0.2em}
\font\myfont=cmr12 at 26pt
\usepackage{anyfontsize}
\usepackage{tabularx}
\usepackage{multirow}
\pagenumbering{arabic} 
\usepackage{soul}
\usepackage{xcolor}
\usepackage[T1]{fontenc}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{blindtext}
\usepackage{titling}
\setlength{\droptitle}{-14em}   % This is your set screw
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{float}
\usepackage{eso-pic}
\graphicspath{ {./images/} }
\usepackage{subcaption}
\usepackage{geometry}
\usepackage[section]{placeins}
\geometry{margin=2cm, bmargin=2cm, tmargin=3cm}

\newcommand{\ctext}[3][RGB]{%
  \begingroup
  \definecolor{hlcolor}{#1}{#2}\sethlcolor{hlcolor}%
  \hl{#3}%
  \endgroup
}


\begin{document}


\AddToShipoutPictureBG*{
\AtPageUpperLeft{
\hspace{19.5cm}
\raisebox{-2.5cm}{\makebox[0pt][r]{\fontsize{36}{1cm}\selectfont DS 2023\par}}}}

\AddToShipoutPictureBG*{
\AtPageUpperLeft{
\hspace{6.5cm}
\raisebox{-3.5cm}{
\makebox[0pt][r]{ 
\includegraphics[scale=0.95]{tecnico_logo.jpg}\\[3cm]}}}}


\title{{\myfont Data Science Project}}  % Title
\setlength{\droptitle}{1cm}

\date{\vspace{-9ex}} % Date for the report, skipped and used to adjust height
\maketitle % Insert the title, author and date
\begin{center}
    %\setlength\extrarowheight{7pt}
    \begin{tabular}{ |l|l l|l| }
        \hline
        \multirow{4}{6em}{\textbf{Team nr: }13} & \textbf{Student 1: } Gonçalo Gonçalves & \textbf{IST nr: }99226\\
        & \textbf{Student 2: } José Cruz & \textbf{IST nr:} 99260 \\
        & \textbf{Student 3: } Jorge Santos & \textbf{IST nr: }99258\\
        & \textbf{Student 4: } Matilde Heitor & \textbf{IST nr: }99284 \\
        \hline
    \end{tabular}
\end{center}

\ctext[RGB]{190,190,190}{The present document presents a template for the Data Science Project report. It specifies the mandatory format and suggests the structure to follow. All text with grey background shall be replaced with the analysis made over the datasets. Put your charts in the \textit{images} folder, and set the name of the file in the \textit{includegraphics} command, after uncommenting it.} 

\begin{center}
	\section*{\fontsize{0.75cm}{1cm}\selectfont CLASSIFICATION}
\end{center}

\section{DATA PROFILING}
\ctext[RGB]{190,190,190}{
  Ds 1 has a lot of records, impacting future decisions.
  Not much preprocessing was done. The \textit{Age} variable in ds 2 had values with the
  character "\_", the character was removed. 
  Other anomalies were kept.
\textbf{Shall not exceed 200 characters.}}

\subsection*{\textit{Data Dimensionality}}
\ctext[RGB]{190,190,190}{
  Both datasets have much more records than variables, avoiding curse of dimensionality.
  \par 
  There are no date variables - no time frame associated . The health dataset predominantly 
  features symbolic variables, particularly binary ones, reflecting the challenge of quantifying 
  clinical observations. The services one is more numerical, demonstrating the precision of its 
  financial context. 
  \par
  In both datasets no variable has more than 20\% missing values, therefore 
  all variables are reasonably interesting.
\textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering
\includegraphics[scale=0.70]{images/dataset1/data_profiling/CovidPos_records_variables.png}
\includegraphics[scale=0.7]{images/dataset2/data_profiling/Credit_Score_records_variables.png}
\caption{Nr Records x Nr variables for dataset 1 (left) and dataset 2 (right)} 
\end{figure}

\begin{figure}[H]
  \includegraphics[scale=0.70]{images/dataset1/data_profiling/CovidPos_variable_types.png}
  \centering\includegraphics[scale=0.7]{images/dataset2/data_profiling/Credit_Score_variable_types.png}
\caption{Nr variables per type for dataset 1 (left) and dataset 2 (right)}
\end{figure}


\begin{figure}[H]
  \includegraphics[scale=0.6]{images/dataset1/data_profiling/CovidPos_mv.png}
  \centering\includegraphics[scale=0.6]{images/dataset2/data_profiling/Credit_Score_mv.png}
\caption{Nr missing values for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\subsection*{\textit{Data Distribution}}
\ctext[RGB]{190,190,190}{  
  Global boxplots depend on the scaling of variables, in our cases, they are pretty much useless
  \par
  All numeric variables have quite high variability in both datasets.
  \par
  The majority of numerical variables follow a normal distribution. 
  \par  
  IQR is more robust to extreme values, more desirable for the study of the second dataset. The stddev is better suited for variables that follow a normal distribution.
  \par
  The class distribution is similar in both datasets, a 25\%-75\%. Some balancing might be required.
\textbf{Shall not exceed 500 characters.}} 

\begin{figure}[H]
  \includegraphics[scale=0.50]{images/dataset1/data_profiling/CovidPos_global_boxplot.png}
  \centering\includegraphics[scale=0.5]{images/dataset2/data_profiling/Credit_Score_global_boxplot.png}
\caption{Global boxplots dataset 1 (left) and dataset 2 (right)}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.60]{images/dataset1/data_profiling/CovidPos_single_boxplots.png}
\caption{Single variables boxplots for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.35]{images/dataset2/data_profiling/Credit_Score_single_boxplots.png}
\caption{Single variables boxplots for dataset 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.6]{images/dataset1/data_profiling/CovidPos_histogram_numeric_distribution.png}
\caption{Histograms for dataset 1} %(with distributions is enough)
\end{figure}
% comment for the histograms with the distributions

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/data_profiling/Credit_Score_histogram_numeric_distribution.png}
\caption{Histograms for dataset 2} %(with distributions is enough)
\end{figure}
% comment for the histograms with the distributions
% talvez tirar os histogramas que nao valem a pena ver????

\begin{figure}[H]
\centering\includegraphics[scale=0.60]{images/dataset1/data_profiling/CovidPos_outliers_standard.png}
\caption{Outliers study dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.40]{images/dataset2/data_profiling/Credit_Score_outliers_standard.png}
\caption{Outliers study dataset 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.95]{images/dataset1/data_profiling/CovidPos_class_distribution.png}
\caption{Class distribution for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.95]{images/dataset2/data_profiling/Credit_Score_class_distribution.png}
\caption{Class distribution for dataset 2}
\end{figure}

\subsection*{\textit{Data Granularity}}
\ctext[RGB]{190,190,190}{
  In dataset 1, the variables \textit{LastCheckupTime}, \textit{State} and \textit{AgeCategory} have 
  interesting taxonomies, allowing for reduction of variance without harming the distribution 
  and information of them.
  \par
  For dataset 2. Some of the variables clearly had too much differente values, this study allowed us to 
  know if descending in the taxonomy hierachy would not signifincantly alter the distribution of 
  these variables. Notable examples of this are the \textit{Type\_of\_Loan} and 
  \textit{Credit\_History\_Age} variables.
\textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/data_preparation/CovidPos_AgeCategory_study_for_granularity.png}
\includegraphics[scale=0.4]{images/dataset1/data_preparation/CovidPos_State_study_for_granularity.png}
\centering\includegraphics[scale=1.0]{images/dataset1/data_preparation/CovidPos_State_per_region_study_for_granularity.png}
\caption{Granularity analysis for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/data_profiling/Credit_Score_granularity.png}
\caption{Granularity analysis for dataset 2}
\end{figure}

\subsection*{\textit{Data Sparsity}}
\ctext[RGB]{190,190,190}{
  Binary on binary is not interesting for sparsity evaluation. We can see which variables have more
  impact on the class and the correlation between them.
  \par
  We encoded the symbolic variables into numeric for the correlation analysis. There are not many 
  variables with high correlation. Even when there is it might not be interesting - gender and height, 
  BMI and weight, Name and ID.
  \par
  In dataset 2 we can infer more information about the behaviour of people and what leads to 
  their credit score.
\textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_State_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_Sex_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_GeneralHealth_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_PhysicalHealthDays_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_MentalHealthDays_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_LastCheckupTime_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_PhysicalActivities_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_SleepHours_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_RemovedTeeth_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HadHeartAttack_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HadAngina_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HadStroke_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HadAsthma_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HadSkinCancer_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HadCOPD_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HadDepressiveDisorder_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HadDepressiveDisorder_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HadKidneyDisease_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HadArthritis_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HadDiabetes_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_DeafOrHardOfHearing_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_BlindOrVisionDifficulty_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_DifficultyConcentrating_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_DifficultyWalking_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_DifficultyDressingBathing_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_DifficultyErrands_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_SmokerStatus_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_ECigaretteUsage_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_ChestScan_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_RaceEthnicityCategory_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_AgeCategory_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HeightInMeters_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_WeightInKilograms_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_BMI_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_AlcoholDrinkers_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_HIVTesting_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_FluVaxLast12_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_PneumoVaxEver_per_class.png}
\includegraphics[scale=0.05]{images/dataset1/data_profiling/CovidPos_sparsity_TetanusLast10Tdap_per_class.png}
\caption{Sparsity analysis for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Month_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Name_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Age_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Occupation_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Annual_Income_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Monthly_Inhand_Salary_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Num_Bank_Accounts_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Num_Credit_Card_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Interest_Rate_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_NumofLoan_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Type_of_Loan_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Delay_from_due_date_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_NumofDelayedPayment_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_ChangedCreditLimit_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_NumCreditInquiries_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_CreditMix_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_OutstandingDebt_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_CreditUtilizationRatio_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Credit_History_Age_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Payment_of_Min_Amount_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_TotalEMIpermonth_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Amountinvestedmonthly_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_Payment_Behaviour_per_class.png}
\includegraphics[scale=0.10]{images/dataset2/data_profiling/Credit_Score_sparsity_MonthlyBalance_per_class.png}
\caption{Sparsity analysis for dataset 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.6]{images/dataset1/data_profiling/CovidPos_correlation_analysis.png}
\caption{Correlation analysis for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.6]{images/dataset2/data_profiling/Credit_Score_correlation_analysis.png}
\caption{Correlation analysis for dataset 2}
\end{figure}

\section{DATA PREPARATION}

\subsection*{\textit{Variables Encoding}}
\ctext[RGB]{190,190,190}{ 
  \par Dataset 1 - Health \par
  In this step all symbolic variables were converted to numeric. All the binary got turned into zeros and ones.
  Ordinal variables preserved their order - \textit{GeneralHealth}, \textit{LastCheckupTime}, \textit{RemovedTeeth},
  \textit{HadDiabetes}, \textit{SmokerStatus}, \textit{ECigaretteUsage}, \textit{AgeCategory} and 
  \textit{TetanusLast10Tdap}. The \textit{State} got its granularity reduced into regions according to the previously done study.

  \par Dataset 2 - Services \par
  In this step we converted all non numerical variables into numerical. For the \textit{ID}, \textit{Customer\_ID},
  \textit{SSN} and \textit{Name} were transformed into numbers, preserving their uniqueness. For variables that had order 
  to their values we used ordinal linear encoding, these were \textit{Credit\_Score}, \textit{Credit\_Mix}, 
  \textit{Payment\_of\_Min\_Amount}, \textit{Credit\_History\_Age} and \textit{Payment\_Behaviour}. For the \textit{Month} we used 
  cyclic encoding. We reduced the granularity of the \textit{Occupation} variable, turning it more broad. For the \textit{Type\_of\_Loan}
  variable we used dummification mixed with the results of the taxonomy evaluation. 
\textbf{Shall not exceed 500 characters \textit{for each dataset.}}}


\subsection*{\textit{Missing Value Imputation}}
\ctext[RGB]{190,190,190}{
  Firstly, we dropped all records with more than 90\% missing values.
  We then applied two different filling strategies, frequence and KNN, which had very 
  similiar results after evaluation (we didn't bother experimenting the constant 
  strategy as it changes the data distribution). The frequence strategy (using mean 
  and mode) came out on top by little, hence our choice to use it to replace the missing 
  values in both datasets.
\textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_mvi_knn_eval.png}
\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_mvi_freq_eval.png}
\caption{Missing values imputation results with different approaches for dataset 1. Frequence (left) and KNN (right) strategies}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.80]{images/dataset2/data_preparation/Credit_Score_mvi_freq_eval.png}
\includegraphics[scale=0.80]{images/dataset2/data_preparation/Credit_Score_mvi_knn_eval.png}
\caption{Missing values imputation results with different approaches for dataset 2}
\end{figure}

\subsection*{\textit{Outliers Treatment}}
\ctext[RGB]{190,190,190}{
  For ds1 the tested strategies significantly worsened the evaluation, particularly the recall, 
  for which we give more attention due to the domain of the data. No modification was applied for ds1. 
  \par
  For ds2 the strategies attained similar results but the best evaluation values were by std
  based dropping (mainly looking at accuracy), this was our choice moving forward. Also, we knew there
  were significant outliers from the profiling study, motivating us to apply a measure to deal with 
  them.
\textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_outliers_treat_rep_fixed_median.png}
\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_outliers_treat_rowDrop_NotStdBased.png}
\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_outliers_treat_rowDrop_StdBased.png}
\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_outliers_treat_truncating_minmax.png}
\caption{Outliers imputation results with different approaches for dataset 1. Rep\_fixed\_median (top left), rowDrop\_NotStdBased (top right), rowDrop\_StdBased (bottom left) and truncating\_minmax (bottom right)}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.8]{images/dataset2/data_preparation/Credit_Score_outliers_treat_rep_fixed_median.png}
\includegraphics[scale=0.8]{images/dataset2/data_preparation/Credit_Score_outliers_treat_rowDrop_NotStdBased.png}
\includegraphics[scale=0.8]{images/dataset2/data_preparation/Credit_Score_outliers_treat_rowDrop_StdBased.png}
\includegraphics[scale=0.8]{images/dataset2/data_preparation/Credit_Score_outliers_treat_truncating_minmax.png}
\caption{Outliers imputation results with different approaches for dataset 2}
\end{figure}


\subsection*{\textit{Scaling}}
\ctext[RGB]{190,190,190}{
  Comparing the MinMax and Z-Score approaches with the original there is little change. 
  MinMax does not handle outliers very well. The scaling chosen was Z-Score as it slightly
  edges the original evaluation results.
  \par
  For dataset 2, we compared the same approaches as in 1, given that both had better accuracys 
  than the original but similar between each other, we opted to scale using Z-Score as it very 
  slightly outperforms MinMax (0-1).    
\textbf{Shall not exceed 200 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_scaling_treat_MinMax1.png}
\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_scaling_treat_MinMax2.png}
\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_scaling_treat_Original.png}
\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_scaling_treat_Z-Score.png}
\caption{Scaling results with different approaches for dataset 1. MinMax[0,1] (top left), MinMax[0,10] (top right), Original (bottom left), Z-Score(bottom right)}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.8]{images/dataset2/data_preparation/Credit_Score_scaling_MinMax.png}
\includegraphics[scale=0.8]{images/dataset2/data_preparation/Credit_Score_scaling_Original.png}
\includegraphics[scale=0.8]{images/dataset2/data_preparation/Credit_Score_scaling_Z-Score.png}
\caption{Scaling results with different approaches for dataset 2}
\end{figure}

\subsection*{\textit{Feature Selection}}
\ctext[RGB]{190,190,190}{
  For ds 1 recall was chosen due to the data domain, we want false negatives to be more influencial
  than false positives. Z-Score turns all variance to 1, chosing a threshold of 1 worsens the results, 22 variables were too litlle relevant.
  Correlation changes don't affect the results, dropped 4 redundant variables.
  \par
  In ds 2 no variable is to be dropped due to their relevancy, threshold lower than 1. In terms of redundacy the best result is as
  well to drop no variables, correlation threshold of 0.57.
\textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.40]{images/dataset1/data_preparation/CovidPos_fs_low_var_recall_study.png}
\includegraphics[scale=0.40]{images/dataset1/data_preparation/CovidPos_fs_redundancy_recall_study.png}
\caption{Feature selection of redundant variables results with different parameters for dataset 1}
\end{figure}



\begin{figure}[H]
\centering\includegraphics[scale=0.70]{images/dataset2/data_preparation/Credit_Score_fs_low_var_accuracy_study_.png}
\includegraphics[scale=0.70]{images/dataset2/data_preparation/Credit_Score_fs_redundancy_accuracy_study.png}
\caption{Feature selection of redundant variables results with different parameters for dataset 2}
\end{figure}


\subsection*{\textit{Balancing}}
\ctext[RGB]{190,190,190}{
  For dataset 1, the SMOTE presented interesting results for recall, but the model was evidently flawed.
  So we chose to balance the data with undersampling, as the set contains a lot of noise 
  (at least 16\% of the records have an outlier value).
  \par
  We chose SMOTE balancing transformation for ds 2.
\textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_balancing_oversampling.png}
\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_balancing_undersampling.png}
\includegraphics[scale=0.80]{images/dataset1/data_preparation/CovidPos_balancing_SMOTE.png}
\caption{Balancing results with different approaches for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.80]{images/dataset2/data_preparation/Credit_Score_balancing_oversampling.png}
\includegraphics[scale=0.80]{images/dataset2/data_preparation/Credit_Score_balancing_undersampling.png}
\includegraphics[scale=0.80]{images/dataset2/data_preparation/Credit_Score_balancing_SMOTE.png}
\caption{Balancing results with different approaches for dataset 2}
\end{figure}

\section{MODELS' EVALUATION}
\ctext[RGB]{190,190,190}{For metric, we pursued recall for the dataset 1, since this means the system values more avoiding FN and maximizing TP. This is ideal because, as we are talking about health, it is always better to be safe than sorry.

For the dataset 2, we chose accuracy as the statistic, because, in this case, it makes sense to have system where we aim to get maximize TP and TN classifications, since a bad decision has a very high cost for the business.

In both datasets we used the hold-out strategy for training.

Shall be used to point out any important decision taken during the training, including training strategy and evaluation measures used.  \textbf{Shall not exceed 500 characters.}}

\subsection*{\textit{Na{\"i}ve Bayes}}
\ctext[RGB]{190,190,190}{For the dataset 1, the Gaussian NB presents the better value, since the majority of numerical variables follow a normal distribution.

For the dataset 2, the Bernoulli NB provides the best results, as the dataset is pretty sparse overall, thus making it harder to follow a normal distribution.

Shall be used to present the results achieved with each one of Na{\"i}ve Bayes implementations, comparing and proposing explanations for them. If any of the implementations is not used, a justification for it shall be presented. Shall be used to present the evaluation of the best model achieved.  \textbf{Shall not exceed 300 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.95]{images/dataset1/models_evaluation/CovidPos_nb_recall_study.png}
\caption{Na{\"i}ve Bayes alternatives comparison for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.95]{images/dataset2/models_evaluation/Credit_Score_nb_accuracy_study.png}
\caption{Na{\"i}ve Bayes alternative comparison for dataset 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/models_evaluation/CovidPos_GaussianNB_best_recall_eval.png}
\includegraphics[scale=0.4]{images/dataset2/models_evaluation/Credit_Score_nb_BernoulliNB_best_accuracy_eval.png}
\caption{Na{\"i}ve Bayes best model results for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\subsection*{\textit{KNN}}
\ctext[RGB]{190,190,190}{For both datasets we decided to limit the search for the best model to a maximum of k=25, due to the computation complexity of the algorithm. 

The best parametrization for the dataset 1 is the Chebyshev, and the model chosen was the k=1, although model is more unstable  and overfitted.

For dataset 2, the best parametrization was the Manhattan with model chosen was k=3. This model is more stable and less specialized than it's previous iterations, resulting in a lower probability for overfitting.

Shall be used to present the results achieved through different similarity measures and KNN parameterisations. The results shall be compared and explanations for them shall be presented. The justification for the chosen similarity measures shall be presented. Shall be used to address the overfitting phenomenon, studying the conditions under which models face it. Shall be used to present the evaluation of the best model achieved.  \textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.95]{images/dataset1/models_evaluation/CovidPos_knn_recall_study.png}
\caption{KNN different parameterisations comparison for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.95]{images/dataset2/models_evaluation/Credit_Score_knn_accuracy_study.png}
\caption{KNN different parameterisations comparison for dataset 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.7]{images/dataset1/models_evaluation/CovidPos_knn_overfitting.png}
\includegraphics[scale=0.7]{images/dataset2/models_evaluation/Credit_Score_knn_overfitting.png}
\caption{KNN overfitting analysis for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/models_evaluation/CovidPos_knn_KNN_best_recall_eval.png}
\includegraphics[scale=0.4]{images/dataset2/models_evaluation/Credit_Score_knn_KNN_best_accuracy_eval.png}
\caption{KNN best model results for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\subsection*{\textit{Decision Trees}}
\ctext[RGB]{190,190,190}{Shall be used to present the results achieved through different parameterisations for the train of decision trees. The results shall be compared and explanations for them shall be presented. Shall be used to address the overfitting phenomenon, studying the conditions under which models face it. Shall be used to present the evaluation of the best model achieved. Shall be used to present the best tree achieved and its succinct description.  \textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.95]{images/dataset1/models_evaluation/CovidPos_DT_accuracy_study.png}
\caption{Decision Trees different parameterisations comparison for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.95]{images/dataset2/models_evaluation/Credit_Score_dt_accuracy_study.png}
\caption{Decision Trees different parameterisations comparison for dataset 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.7]{images/dataset1/models_evaluation/CovidPos_dt_accuracy_overfitting.png}
\includegraphics[scale=0.7]{images/dataset2/models_evaluation/Credit_Score_DT_overfitting.png}
\caption{Decision Trees overfitting analysis for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/models_evaluation/CovidPos_dt_DT_best_accuracy_eval.png}
\includegraphics[scale=0.4]{images/dataset2/models_evaluation/Credit_Score_DT_best_accuracy_eval.png}
\caption{Decision trees best model results for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.50]{images/dataset1/models_evaluation/CovidPos_dt_accuracy_best_tree.png}
\caption{Best tree for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/models_evaluation/Credit_Score_DT_best_tree.png}
\caption{Best tree for dataset 2}
\end{figure}

\subsection*{\textit{Random Forests}}
\ctext[RGB]{190,190,190}{Shall be used to present the results achieved through different parameterisations for the train of random forests. The results shall be compared and explanations for them shall be presented. Shall be used to address the overfitting phenomenon, studying the conditions under which models face it. Shall be used to present the evaluation of the best model achieved. May be used to present the most important variables in the model.  \textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.6]{images/dataset1/models_evaluation/CovidPos_rf_recall_study.png}
\includegraphics[scale=0.6]{images/dataset1/models_evaluation/CovidPos_rf_accuracy_study.png}
\includegraphics[scale=0.6]{images/dataset1/models_evaluation/CovidPos_rf_f1_study.png}
\includegraphics[scale=0.6]{images/dataset1/models_evaluation/CovidPos_rf_precision_study.png}
\includegraphics[scale=0.6]{images/dataset1/models_evaluation/CovidPos_rf_auc_study.png}
\caption{Random Forests different parameterisations comparison for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.6]{images/dataset2/models_evaluation/Credit_Score_rf_recall_study.png}
\includegraphics[scale=0.6]{images/dataset2/models_evaluation/Credit_Score_rf_accuracy_study.png}
\includegraphics[scale=0.6]{images/dataset2/models_evaluation/Credit_Score_rf_f1_study.png}
\includegraphics[scale=0.6]{images/dataset2/models_evaluation/Credit_Score_rf_precision_study.png}
\includegraphics[scale=0.6]{images/dataset2/models_evaluation/Credit_Score_rf_auc_study.png}
\caption{Random Forests different parameterisations comparison for dataset 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.7]{images/dataset1/models_evaluation/CovidPos_rf_f1_overfitting.png}
\includegraphics[scale=0.7]{images/dataset2/models_evaluation/Credit_Score_rf_accuracy_overfitting.png}
\caption{Random Forests overfitting analysis for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/models_evaluation/CovidPos_rf_RF_best_recall_eval.png}
\includegraphics[scale=0.4]{images/dataset2/models_evaluation/Credit_Score_rf_RF_best_accuracy_eval.png}
\caption{Random Forests best model results for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.7]{images/dataset1/models_evaluation/CovidPos_rf_recall_vars_ranking.png}
\includegraphics[scale=0.7]{images/dataset2/models_evaluation/Credit_Score_rf_accuracy_vars_ranking.png}
\caption{Random Forests variables importance for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\subsection*{\textit{Gradient Boosting}}
\ctext[RGB]{190,190,190}{Shall be used to present the results achieved through different parameterisations for the train of gradient boosting. The results shall be compared and explanations for them shall be presented. Shall be used to address the overfitting phenomenon, studying the conditions under which models face it.  Shall be used to present the evaluation of the best model achieved. May be used to present the most important variables in the model.  \textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.60]{images/dataset1/models_evaluation/CovidPos_gb_recall_study.png}
\includegraphics[scale=0.60]{images/dataset1/models_evaluation/CovidPos_gb_accuracy_study.png}
\includegraphics[scale=0.60]{images/dataset1/models_evaluation/CovidPos_gb_f1_study.png}
\includegraphics[scale=0.60]{images/dataset1/models_evaluation/CovidPos_gb_precision_study.png}
\includegraphics[scale=0.60]{images/dataset1/models_evaluation/CovidPos_gb_auc_study.png}
\caption{Gradient boosting different parameterisations comparison for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.60]{images/dataset2/models_evaluation/Credit_Score_gb_study.png}
\caption{Gradient boosting different parameterisations comparison for dataset 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.7]{images/dataset1/models_evaluation/CovidPos_gb_accuracy_overfitting.png}
\includegraphics[scale=0.7]{images/dataset2/models_evaluation/Credit_Score_gb_accuracy_overfitting.png}
\caption{Gradient boosting overfitting analysis for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/models_evaluation/CovidPos_gb_GB_best_recall_eval.png}
\includegraphics[scale=0.4]{images/dataset2/models_evaluation/Credit_Score_gb_best_model_performance_accuracy.png}
\caption{Gradient boosting best model results for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.7]{images/dataset1/models_evaluation/CovidPos_gb_recall_vars_ranking.png}
\includegraphics[scale=0.7]{images/dataset2/models_evaluation/Credit_Score_gb_accuracy_vars_ranking.png}
\caption{Gradient boosting variables importance for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\subsection*{\textit{Multi-Layer Perceptrons}}
\ctext[RGB]{190,190,190}{For dataset 1, the model learnt is not useful, with 1.0 recall, every predicted value is positive. This means that recall is clearly not the right measure to optimize. While the recall over the training set is constant, on the test it oscilates periodically with no evident improvement or decrease, could be due to high amounts of noise.
For dataset 2, although the model might be on a slight overfit, especially from the 800th iteration, the high values on all metrics indicate that it's a good model. \textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.6]{images/dataset1/models_evaluation/CovidPos_mlp_recall_study.png}
% \includegraphics[scale=0.45]{images/dataset1/models_evaluation/CovidPos_mlp_accuracy_study.png}
% \includegraphics[scale=0.45]{images/dataset1/models_evaluation/CovidPos_mlp_f1_study.png}
% \includegraphics[scale=0.45]{images/dataset1/models_evaluation/CovidPos_mlp_precision_study.png}
% \includegraphics[scale=0.45]{images/dataset1/models_evaluation/CovidPos_mlp_auc_study.png}
\caption{MLP different parameterisations comparison for dataset 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.6]{images/dataset2/models_evaluation/Credit_Score_mlp_accuracy_study.png}
% \includegraphics[scale=0.45]{images/dataset2/models_evaluation/Credit_Score_mlp_recall_study.png}
% \includegraphics[scale=0.45]{images/dataset2/models_evaluation/Credit_Score_mlp_f1_study.png}
% \includegraphics[scale=0.45]{images/dataset2/models_evaluation/Credit_Score_mlp_precision_study.png}
% \includegraphics[scale=0.45]{images/dataset2/models_evaluation/Credit_Score_mlp_auc_study.png}
\caption{MLP different parameterisations comparison for dataset 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.7]{images/dataset1/models_evaluation/CovidPos_mlp_recall_overfitting.png}
\includegraphics[scale=0.7]{images/dataset2/models_evaluation/Credit_Score_mlp_accuracy_overfitting.png}
\caption{MLP overfitting analysis for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/models_evaluation/CovidPos_mlp_MLP_best_recall_eval.png}
\includegraphics[scale=0.4]{images/dataset2/models_evaluation/Credit_Score_mlp_MLP_best_accuracy_eval.png}
\caption{MLP best model results for dataset 1 (left) and dataset 2 (right)}
\end{figure}

\section{CRITICAL ANALYSIS}
\ctext[RGB]{190,190,190}{Shall be used to present a summary of the results achieved with the different modelling techniques, and the impact of the different preparation tasks on their performance. 
A cross-analysis of the different models may also be presented, identifying the most relevant variables common to all of them (when possible) and the relation among the patterns identified within the different classifiers.
A critical assessment of the best models shall be presented, clearly stating if the models seem to be good enough for the problem at hand. \textbf{Additional charts may be presented here.  Shall not exceed 2000 characters.}}

remember that an outlier is a point that is far away from the regular ones. Given that for all but the \textit{MonthlyBalance} 
variable all the points are continuous, some care must be taken in their treatment.


\begin{center}
	\section*{\fontsize{0.75cm}{1cm}\selectfont TIME SERIES ANALYSIS}
\end{center}

\section{DATA PROFILING}

\subsection*{\textit{Data Dimensionality and Granularity}}
\ctext[RGB]{190,190,190}{We used the "sum" function as "agg\_fun" for both datasets. We studied the granularity at three different levels, for dataset 1, weekly (atomic), monthly and quarterly with an upwards trend but no seasonality or cyclical behaviour. For dataset 2 by 15 minutes (atomic), hourly and daily, with no visible trend, daily seasonality on each morning and evening and also weekly cyclicality with a busier day a week (usually Mondays except the first spike) both corresponding to heavier traffic flows. \textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_granularity_aggregation_W.png}
\caption{Time series 1 at the most granular detail}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_granularity_aggregation_M.png}
\caption{Time series 1 at the second chosen granularity}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_granularity_aggregation_Q.png}
\caption{Time series 1 at the third chosen granularity}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/time_series/fts_granularity_min.png}
\caption{Time series 2 at the most granular detail}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/time_series/fts_granularity_H.png}
\caption{Time series 2 at the second chosen granularity}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/time_series/fts_granularity_D.png}
\caption{Time series 2 at the third chosen granularity}
\end{figure}

\subsection*{\textit{Data Distribution}}
\ctext[RGB]{190,190,190}{Shall be used to perform the data analysis at those three different granularities, concerning the series distribution.  \textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.80]{images/dataset1/time_series/Covid_distribution_boxplot.png}
\caption{Boxplot(s) for time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.8]{dataset2/time_series/fts_boxplot.png}
\caption{Boxplot(s) for time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{dataset1/time_series/Covid_distribution_histogram.png}
\caption{Histogram(s) for time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.50]{images/dataset2/time_series/fts_histogram.png}
\caption{Histogram(s) for time series 2}
\end{figure}

\subsection*{\textit{Data Stationarity}}
\ctext[RGB]{190,190,190}{For the 1st dataset we obtained a p-value of 0.223. Looking at the graphs, we can see that there is a trend in the first 2 and that there is evidence of a seasonal trend in the 3rd. For the 2nd dataset we obtained a p-value of 0. and that there is no trend but there is some seasonality.  \textbf{Shall not exceed 300 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.50]{images/dataset1/time_series/Covid_components_study.png}
\caption{Components study for time series 1}
\end{figure}


\begin{figure}[H]
\centering\includegraphics[scale=0.6]{images/dataset1/time_series/Covid_stationarity_study_1.png}
\includegraphics[scale=0.6]{images/dataset1/time_series/Covid_stationarity_study_2.png}
\caption{Stationarity study for time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.50]{images/dataset2/time_series/fts_components_study.png}
\caption{Components study for time series 2}
\end{figure}


\begin{figure}[H]
\centering\includegraphics[scale=0.6]{images/dataset2/time_series/fts_stationarity_study_1.png}
\includegraphics[scale=0.6]{images/dataset2/time_series/fts_stationarity_study_2.png}
\caption{Stationarity study for time series 2}
\end{figure}

\section{DATA TRANSFORMATION}

\subsection*{\textit{Aggregation}}
\ctext[RGB]{190,190,190}{To study the best aggregation, we applied the model at 3 different levels studied in Data Profiling. In dataset 1, chose the weekly aggregation and for dataset 2, hourly aggregation as they obtained lower values for the different errors, simplifying the model without losing information or context.  \textbf{Shall not exceed 300 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/time_series/Covid Weekly - Linear Regression_forecasting_series.png}
\includegraphics[scale=0.4]{images/dataset1/time_series/Covid Monthly - Linear Regression_forecasting_series.png}
\includegraphics[scale=0.4]{images/dataset1/time_series/Covid Quarterly - Linear Regression_forecasting_series.png}
\caption{Forecasting plots after different aggregations on time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_Weekly - Linear Regression_forecasting_eval.png}
\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_Monthly - Linear Regression_forecasting_eval.png}
\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_Quarterly - Linear Regression_forecasting_eval.png}
\caption{Forecasting results after different aggregations on time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_linear_regression_forecast_Minutely.png}
\includegraphics[scale=0.4]{images/dataset2/time_series/fts_linear_regression_forecast_Hourly.png}
\includegraphics[scale=0.4]{images/dataset2/time_series/fts_linear_regression_forecast_Daily.png}
\caption{Forecasting plots after different aggregations on time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/time_series/fts_linear_regression_eval_Minutely.png}
\includegraphics[scale=0.5]{images/dataset2/time_series/fts_linear_regression_eval_Hourly.png}
\includegraphics[scale=0.5]{images/dataset2/time_series/fts_linear_regression_eval_Daily.png}
\caption{Forecasting results after different aggregations on time series 2}
\end{figure}

\subsection*{\textit{Smoothing}}
\ctext[RGB]{190,190,190}{To study the best Window Size, we applied the model to 4 different values (25, 50, 75 and 100). In this case we chose 100 for both datasets since it was where we obtained the lowest values for the different errors.  \textbf{Shall not exceed 300 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/time_series/Covid Window Size 25 - Linear Regression_forecasting_series.png}
\includegraphics[scale=0.4]{images/dataset1/time_series/Covid Window Size 50 - Linear Regression_forecasting_series.png}
\includegraphics[scale=0.4]{images/dataset1/time_series/Covid Window Size 75 - Linear Regression_forecasting_series.png}
\includegraphics[scale=0.4]{images/dataset1/time_series/Covid Window Size 100 - Linear Regression_forecasting_series.png}
\caption{Forecasting plots after different smoothing parameterisations on time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_Window_Size_25 - Linear Regression_forecasting_eval.png}
\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_Window_Size_50 - Linear Regression_forecasting_eval.png}
\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_Window_Size_75 - Linear Regression_forecasting_eval.png}
\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_Window_Size_100 - Linear Regression_forecasting_eval.png}
\caption{Forecasting results after different smoothing parameterisations on time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_forecast_ts_after_smooth_ws_25.png}
\includegraphics[scale=0.4]{images/dataset2/time_series/fts_forecast_ts_after_smooth_ws_50.png}
\includegraphics[scale=0.4]{images/dataset2/time_series/fts_forecast_ts_after_smooth_ws_75.png}
\includegraphics[scale=0.4]{images/dataset2/time_series/fts_forecast_ts_after_smooth_ws_100.png}
\caption{Forecasting plots after different smoothing parameterisations on time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/time_series/fts_forecast_eval_after_smooth_ws_25.png}
\includegraphics[scale=0.5]{images/dataset2/time_series/fts_forecast_eval_after_smooth_ws_50.png}
\includegraphics[scale=0.5]{images/dataset2/time_series/fts_forecast_eval_after_smooth_ws_75.png}
\includegraphics[scale=0.5]{images/dataset2/time_series/fts_forecast_eval_after_smooth_ws_100.png}
\caption{Forecasting results after different smoothing parameterisations on time series 2}
\end{figure}

\subsection*{\textit{Differentiation}}
\ctext[RGB]{190,190,190}{To study differentiation, we applied the first two derivatives, favoring the first one for both datasets. In dataset 1, it helped remove quadratic trends and minimize the errors and for dataset 2, both derivatives removed seasonality, but the second added complexity, making it harder to predict. \textbf{Shall not exceed 300 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/time_series/Covid First derivative - Linear Regression_forecasting_series.png}
\includegraphics[scale=0.4]{images/dataset1/time_series/Covid Second derivative - Linear Regression_forecasting_series.png}
\caption{Forecasting plots after first and second differentiation of time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_First derivative - Linear Regression_forecasting_eval.png}
\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_Second derivative - Linear Regression_forecasting_eval.png}
\caption{Forecasting results after first and second differentiation of time series 1}
\end{figure}

\begin{figure}[H]
%\centering\includegraphics[scale=0.95]{}
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_forecast_ts_FirstDerivative.png}
\includegraphics[scale=0.4]{images/dataset2/time_series/fts_forecast_ts_SecondDerivative.png}
\caption{Forecasting plots after first and second differentiation of time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/time_series/fts_forecast_eval_FirstDerivative.png}
\includegraphics[scale=0.5]{images/dataset2/time_series/fts_forecast_eval_SecondDerivative.png}
\caption{Forecasting results after first and second differentiation of time series 2}
\end{figure}

\subsection*{\textit{Other transformations (optional)}}
\ctext[RGB]{190,190,190}{Finally, we applied scaling in both datasets in order to have best values to use in the models' evaluation specifically in the LSTM model.  \textbf{Shall not exceed 500 characters.}}

\begin{figure}[H]
\centering\includegraphics[scale=0.6]{images/dataset1/time_series/Covid_deaths_scaling.png}
\caption{Forecasting plots after applying scaling over time series 1}
\end{figure}

\begin{figure}[H]
%\centering\includegraphics[scale=0.95]{}
\caption{Forecasting results after applying other transformations over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.6]{images/dataset2/time_series/fts_Total_scaling.png}
\caption{Forecasting plots after applying other transformations over time series 2}
\end{figure}

\begin{figure}[H]
%\centering\includegraphics[scale=0.95]{}
\caption{FForecasting results after applying other transformations over time series 2}
\end{figure}

\section{MODELS' EVALUATION}
\ctext[RGB]{190,190,190}{For the first dataset we used the weekly aggregation with window size=100, the first derivative and then applied scaling. For dataset 2 we selected minutely aggregation, window size=100, first derivative and scaling. Results were surprisingly positive for dataset 1 when applying the linear regression compared to dataset 2 as the last is closer to the shape of a cosine function instead of linear. For the aggregation study, higher levels were not selected due to high loss of information.}

\subsection*{\textit{Simple Average Model}}
\ctext[RGB]{190,190,190}{Although this metric doesn't approximate any of the datasets correctly, the error and R2 values for dataset 2 seem better because there are some contact points between the real and predicted values.}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/time_series/Covid - Simple Average_forecasting_series.png}
\caption{Forecasting plots obtained with Simple Average model over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid - Simple Average_forecasting_eval.png}
\caption{Forecasting results obtained with Simple Average model over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_simpleAvg_forecast.png}
\caption{Forecasting plots obtained with Simple Average model over time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/time_series/fts_simpleAvg_eval.png}
\caption{Forecasting results obtained with Simple Average model over time series 2}
\end{figure}

\subsection*{\textit{Persistence Model}}
\ctext[RGB]{190,190,190}{The persistence model analysis displays bad results for the realist model and very good results for the optimistic. However, the optimistic model isn't capable to make long-term predictions, it can only accurately predict on a short term space whereas the realist model approximates for long distance. For these reasons, both are bad models for the datasets.}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/time_series/Covid - Persistence Realist_forecasting_series.png}
\caption{Forecasting plots obtained with Persistence model (long term) over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/time_series/Covid - Persistence Optimist_forecasting_series.png}
\caption{Forecasting plots obtained with Persistence model (one-set-behind) over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid - Persistence Optimist_forecasting_eval.png}
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid - Persistence Realist_forecasting_eval.png}
\caption{Forecasting results obtained with Persistence model in both situations over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_persistence_real_forecast.png}
\caption{Forecasting plots obtained with Persistence model (long term) over time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_persistence_optim_forecast.png}
\caption{Forecasting plots obtained with Persistence model (one-set-behind) over time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/time_series/fts_persistence_real_eval.png}
\centering\includegraphics[scale=0.5]{images/dataset2/time_series/fts_persistence_optim_eval.png}
\caption{Forecasting results obtained with Persistence model in both situations over time series 2}
\end{figure}

\subsection*{\textit{Rolling Mean Model}}
\ctext[RGB]{190,190,190}{Although this metric doesn't approximate any of the datasets correctly, the first dataset obtains better results for the MAE, RMSE and MAPE as it predicts values closer to the real ones but doesn't predict any correct value while dataset 2 has a better R2 because it fluctuates between somewhat symmetric high and low values obtaining a horizontal line between them so there are some contact points but the line remains very distant from the minimum and maximum points.}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid_rollingmean_R2_study.png}
\caption{Forecasting study over different parameterisations of the rolling mean algorithm over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/time_series/Covid - Rolling Mean (win=3)_forecasting_series.png}
\caption{Forecasting plots obtained with the best parameterisation of rolling mean algorithm, over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid - Rolling Mean (win=3)_forecasting_eval.png}
\caption{Forecasting results obtained with the best parameterisation of rolling mean algorithm, over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_rollingmean_R2_study.png}
\caption{Forecasting study over different parameterisations of the rolling mean algorithm over time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_rollingmean_R2_forecast.png}
\caption{Forecasting plots obtained with the best parameterisation of rolling mean algorithm, over time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_rollingmean_R2_win20_eval.png}
\caption{Forecasting results obtained with the best parameterisation of rolling mean algorithm, over time series 2}
\end{figure}

\subsection*{\textit{ARIMA Model}}
\ctext[RGB]{190,190,190}{Dataset 1, with a trend-style pattern, benefits from parameters (p, d, q) set to (7, 2, 5). This configuration allows the model to capture and accommodate the complexities associated with trend-based data. On the other hand, Dataset 2, exhibiting a cosine-like shape, attains superior performance with parameters at (3, 0, 5). This parameter choice enables the model to capture the cyclical and periodic components in the dataset, showcasing the adaptability of ARIMA to diverse time series patterns.}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/time_series/Covid_arima_R2_study.png}
\caption{Forecasting study over different parameterisations of the ARIMA algorithm over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/time_series/Covid - ARIMA _forecasting_series.png}
\caption{Forecasting plots obtained with the best parameterisation of ARIMA algorithm, over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid - ARIMA (p=7, d=2, q=5)_forecasting_eval.png}
\caption{Forecasting results obtained with the best parameterisation of ARIMA algorithm, over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_arima_R2_study.png}
\caption{Forecasting study over different parameterisations of the ARIMA algorithm over time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_arima_R2_forecast.png}
\caption{Forecasting plots obtained with the best parameterisation of ARIMA algorithm, over time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/time_series/fts_arima_R2_eval.png}
\caption{Forecasting results obtained with the best parameterisation of ARIMA algorithm, over time series 2}
\end{figure}

\subsection*{\textit{LSTMs Model}}
\ctext[RGB]{190,190,190}{For Dataset 1, having a trend, the LSTM excels with parameters length=4, hidden=100 and nr\_episodes=900, effectively capturing trend-oriented patterns. This adaptability extends to Dataset 2, featuring a cosine-like trend, where the same parameter configuration yields optimal results. As expected the LSTM's model achieves the best forecasting results for both datasets compared to the previous models.}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/time_series/Covid_lstm_study_R2.png}
\caption{Forecasting study over different parameterisations of LSTMs over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset1/time_series/Covid - LSTMs _forecasting_series.png}
\caption{Forecasting plots obtained with the best parameterisation of LSTMs, over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset1/time_series/Covid - LSTM (length=4, hidden=100, epochs=900)_forecasting_eval.png}
\caption{Forecasting results obtained with the best parameterisation of LSTMs, over time series 1}
\end{figure}

\begin{figure}[H]
%\centering\includegraphics[scale=0.95]{}
\caption{Forecasting study over different parameterisations of LSTMs with multiple variables over time series 1}
\end{figure}

\begin{figure}[H]
%\centering\includegraphics[scale=0.95]{}
\caption{Forecasting plots obtained with the best parameterisation of LSTMs with multiple variables over time series 1}
\end{figure}

\begin{figure}[H]
%\centering\includegraphics[scale=0.95]{}
\caption{Forecasting results obtained with the best parameterisation of LSTMs with multiple variables over time series 1}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_lstm_study_R2_8.png}
\caption{Forecasting study over different parameterisations of the LSTMs over time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.4]{images/dataset2/time_series/fts_lstms_R2_forecast.png}
\caption{Forecasting plots obtained with the best parameterisation of LSTMs, over time series 2}
\end{figure}

\begin{figure}[H]
\centering\includegraphics[scale=0.5]{images/dataset2/time_series/fts_lstms_R2_eval.png}
\caption{Forecasting results obtained with the best parameterisation of LSTMs, over time series 2}
\end{figure}

\begin{figure}[H]
%\centering\includegraphics[scale=0.95]{}
\caption{Forecasting study over different parameterisations of LSTMs with multiple variables over time series 2}
\end{figure}

\begin{figure}[H]
%\centering\includegraphics[scale=0.95]{}
\caption{Forecasting plots obtained with the best parameterisation of LSTMs with multiple variables over time series 2}
\end{figure}

\begin{figure}[H]
%\centering\includegraphics[scale=0.95]{}
\caption{Forecasting results obtained with the best parameterisation of LSTMs with multiple variables over time series 2}
\end{figure}

\section{CRITICAL ANALYSIS}
\ctext[RGB]{190,190,190}{In a critical assessment, both ARIMA and LSTMs outperformed simpler models like simple average or rolling mean, emphasizing their adaptability and effectiveness. LSTMs, in particular, demonstrated superior performance across diverse datasets, positioning them as a favorable choice for both. The decision between these strands hinges on dataset specifics and the desired trade-off between interpretability and complexity.
Dataset 1 reveals a non-stationary nature, characterized by an initial upward trend with it slowing down. Although on the smoothing phase this shape is flattened, this decline in Covid related death rates can be seen on the differentiation analysis, by employing the second derivative and removing the quadratic trend, recalling the beginning upwards activity and settling down later. In order to have best suited values for the LSTM model, we applied scaling.  Notably, although we predicted it to be a good fit for this model, ARIMA is not a suitable fit for this series as it's prediction is too long-term based, not dealing with the abrupt decline.
For dataset 2, also non-stationary, having applied both smoothing, differentiation and scaling to regularise the value spikes and revealing cyclical and seasonal behaviors of this series, but with no evident trend. As expected but differing from the first dataset, the ARIMA model provides a good fit, encapsulating the cyclicality of this series on a good level. Despite not being as accurate as LSTM, if the model complexity from the latest proves a bottleneck for the problem, ARIMA is a good substitute.
The univariate nature of the time series hinders accurate prediction, leading to suboptimal model performance. For this reason and as the simple average model, persistence realist and optimist and rolling mean can only deal with linear series or short term predictions which are not the case for either datasets, none of these models seem good enough to solve these problems. \textbf{Shall not exceed 2000 characters.}}

\end{document}
